{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL2Y-R2cSRRx"
      },
      "source": [
        "<h1><font color=\"#113D68\" size=6>Deep Learning con Python y Keras VIDEO</font></h1>\n",
        "\n",
        "<h1><font color=\"#113D68\" size=5>Redes Neuronales Convolucionales</font></h1>\n",
        "\n",
        "<h1><font color=\"#113D68\" size=4>Reconocimiento de dígitos</font></h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLQjLiSoSRRz"
      },
      "source": [
        "---\n",
        "\n",
        "<a id=\"indice\"></a>\n",
        "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
        "\n",
        "* [0. Contexto](#section0)\n",
        "* [1. MNIST dataset](#section1)\n",
        "* [2. Cargar MNIST](#section2)\n",
        "* [3. Modelo de línea de base con MLP](#section3)\n",
        "* [4. Prediccion de datos](#section4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44g6jqHaSRRz"
      },
      "source": [
        "---\n",
        "<a id=\"section0\"></a>\n",
        "# <font color=\"#004D7F\" size=6> 0. Contexto</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqZE0Q1pSRR0"
      },
      "source": [
        "En este proyecto, descubrirá cómo desarrollar un modelo de Deep Learning en la tarea de reconocimiento de dígitos manuscritos del MNIST. Después de completar este trabajo sabrá:\n",
        "* Cómo cargar MNIST y desarrollar un modelo de red neuronal.\n",
        "* Cómo implementar un modelo de Deep Learning avanzado para MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "1QXC31fdSRR0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1apdrtcwSRR1"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WavhM1dJSRR1"
      },
      "source": [
        "<a id=\"section1\"></a>\n",
        "# <font color=\"#004D7F\" size=6>1. MNIST dataset</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J2-A6TFSRR1"
      },
      "source": [
        "MNIST toma imágenes de dígitos de una variedad de documentos escaneados, normalizados en tamaño y centrados.\n",
        "\n",
        "Cada imagen es está dada en blanco y negro con $28 × 28$ píxeles (784 píxeles en total). Se usan 60,000 imágenes para entrenar un modelo y 10,000 imágenes para validarlo.\n",
        "\n",
        "Es una tarea de reconocimiento de dígitos. Como tal, hay 10 dígitos (0 a 9) o 10 clases para predecir. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4U8Gh4fSRR1"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
        "Más información sobre el dataset [MNIST](http://yann.lecun.com/exdb/mnist/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu007ymqSRR2"
      },
      "source": [
        "<a id=\"section2\"></a>\n",
        "# <font color=\"#004D7F\" size=6>2. Cargar MNIST</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ40B-A8SRR2"
      },
      "source": [
        "El conjunto de datos se descarga automáticamente la primera vez que se llama a esta función como un archivo de 15 megabytes. \n",
        "\n",
        "Primero escribiremos un pequeño script para descargar y visualizar las primeras 4 imágenes mediante la función `mnist.load data()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "pPFLJeSPSRR2",
        "outputId": "1ebc4156-b9d6-4453-b538-de28ac9f226b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD7CAYAAAAVQzPHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWyklEQVR4nO3de4wUVfYH8O8BwRcBHdYMkwFBzQiOv6AoIqIRFDAsooOiKAHBSBgTIAElZtFFozEiKpKIT1ARUAJugghqiLI4ihtxAiju8hAGTcDBAQTlISAsen5/THmtWzs903RXV1X3/X6SSZ/bl+46ModjvUtUFUREha5Z3AkQEUWBzY6InMBmR0ROYLMjIiew2RGRE9jsiMgJWTU7ERkgIltEZJuITA4rKaK4sbYLj2R6np2INAewFUB/ALUA1gAYpqqbwkuPKHqs7cJ0Shaf7QFgm6p+BwAisghABYCUBSEiPIM5Ofaq6jlxJ5FQJ1XbrOtESVnX2WzGlgL43jeu9d6j/LA97gQSjLWdv1LWdTZrdmkRkUoAlbleDlGUWNf5J5tmtxNAB9+4vfeeRVVnA5gNcHWf8kaTtc26zj/ZbMauAVAmIueJSEsAdwJYFk5aRLFibRegjNfsVPWEiIwH8CGA5gDmqOrG0DIjiglruzBlfOpJRgvj6n6SrFPV7nEnUQhY14mSsq55BQUROYHNjoicwGZHRE5gsyMiJ7DZEZET2OyIyAlsdkTkhJxfG0tE+efyyy+3xuPHjzfxyJEjrbn58+eb+Pnnn7fmvvzyyxxklxmu2RGRE9jsiMgJbHZE5AReG9uA5s2bW+M2bdqk/Vn/vo0zzjjDmuvcubOJx40bZ81Nnz7dxMOGDbPmfv31VxNPmzbNmnvsscfSzi2A18aGJF/qujGXXnqpNf7444+tcevWrdP6ngMHDljjtm3bZpfYyeO1sUTkNjY7InJCQZ96cu6551rjli1bmrhXr17W3DXXXGPis846y5obMmRIKPnU1taaeObMmdbcLbfcYuJDhw5Zc19//bWJP/3001ByIerRo4eJFy9ebM0Fd934d3cF6/P48eMmDm629uzZ08TB01D8n4sC1+yIyAlsdkTkBDY7InJCwZ164j+EHjx8fjKnkITh999/t8b33HOPiX/55ZeUn6urq7PGP//8s4m3bNkSUnY89SQsST71xH/602WXXWbNvfXWWyZu3769NSci1tjfJ4L73p5++mkTL1q0KOX3TJkyxZp78sknG809Qzz1hIjcxmZHRE4ouFNPduzYYeJ9+/ZZc2FsxlZXV1vj/fv3W+PrrrvOxMFD62+++WbWyyc6GbNmzTJx8MqcTAU3h1u1amXi4KlRffr0MXHXrl1DWX6muGZHRE5gsyMiJ7DZEZETCm6f3U8//WTiBx54wJobNGiQib/66itrLnj5lt/69etN3L9/f2vu8OHD1vjiiy828YQJE9LImCg8wTsM33jjjSYOnk7iF9zX9t5771lj/115fvjhB2vO/2/Jf5oUAFx//fVpLT8KTa7ZicgcEdkjIht87xWJyAoRqfFez85tmkThY227JZ3N2LkABgTemwxgpaqWAVjpjYnyzVywtp2R1hUUItIJwPuq+n/eeAuAPqpaJyIlAD5R1c6NfMUf3xPrmeb+GxAG79zgP0Q/evRoa27EiBEmXrhwYY6yixyvoEA4tR13XTd21VBjN91cvny5iYOnpfTu3dsa+08bee2116y5H3/8MeUyfvvtNxMfOXIk5TJCfDBP6FdQFKvqH9c07QJQnOH3ECUNa7tAZX2AQlW1sf+ziUglgMpsl0MUtcZqm3WdfzJds9vtreLDe92T6g+q6mxV7c5NJsoTadU26zr/ZLpmtwzAKADTvNeloWWUQwcPHkw5F3xQiN+YMWNM/Pbbb1tzwTubUN5LfG1feOGF1th/ilXwksi9e/eaOHg3nXnz5pk4eBeeDz74oNFxJk4//XRrPGnSJBMPHz486+9vSjqnniwEsBpAZxGpFZHRqC+E/iJSA6CfNybKK6xttzS5Zqeqqa4e7htyLkSRYm27peCuoMjUo48+auLgWej+Q+T9+vWz5j766KOc5kUEAKeeeqqJ/VczAMDAgQNNHDylauTIkSZeu3atNRfcrIxa8IFYucZrY4nICWx2ROQENjsicgL32Xn8dy/xn2oC2JeyvPrqq9ZcVVWVNfbvF3nxxRetuSgfbkSFpVu3bib276MLqqiosMZ8qPqfuGZHRE5gsyMiJ3AztgHffvutNb777rtN/MYbb1hzd911V8rxmWeeac3Nnz/fxMGz2YkaM2PGDBMHb4Lp31RN2mZrs2Z/rk/FfbUR1+yIyAlsdkTkBDY7InIC99mlYcmSJSauqamx5vz7UgCgb98/L6ucOnWqNdexY0cTP/HEE9bczp07s86TCof/4VCAfTfi4ClMy5YtiySnTPj30wXz9j/IKgpcsyMiJ7DZEZET2OyIyAncZ3eSNmzYYI2HDh1qjW+66SYTB8/Ju/fee01cVlZmzQUfvk1uC95+qWXLlibes8e+U3zw7tlR899+yn+rtKDgk88efPDBXKXUIK7ZEZET2OyIyAncjM3S/v37rfGbb75p4uDDhE855c+/7muvvdaa69Onj4k/+eST8BKkgnPs2DFrHPWlh/7NVgCYMmWKif0P/wGA2tpaEz/77LPWXPAhP7nGNTsicgKbHRE5gc2OiJzAfXYnqWvXrtb4tttus8ZXXHGFif376II2bdpkjVetWhVCduSCOC4P81+uFtwvd8cdd5h46VL7meJDhgzJbWIngWt2ROQENjsicgI3YxvQuXNnazx+/HgT33rrrdZcu3bt0v7e3377zcTB0wXivosrJUvwbsT+8eDBg625CRMmhL78++67zxo//PDDJm7Tpo01t2DBAhP7H8qdNFyzIyInNNnsRKSDiFSJyCYR2SgiE7z3i0RkhYjUeK9n5z5dovCwtt2SzprdCQCTVLUcQE8A40SkHMBkACtVtQzASm9MlE9Y2w5pcp+dqtYBqPPiQyKyGUApgAoAfbw/Ng/AJwD+lpMscyC4r23YsGEm9u+jA4BOnTpltAz/A7MB++7ESb67rCuSXNvBu/r6x8HanTlzponnzJljze3bt8/EPXv2tOb8T8K75JJLrLn27dtb4x07dpj4ww8/tOZeeuml//0PSKCT2mcnIp0AdANQDaDYKxYA2AWgONTMiCLE2i58aR+NFZFWABYDmKiqB/1Hh1RVRURTfK4SQGW2iRLlSia1zbrOP2k1OxFpgfpiWKCq73hv7xaRElWtE5ESAHsa+qyqzgYw2/ueBhtirhQX2/9DLi8vN/ELL7xgzXXp0iWjZVRXV1vjZ555xsTBs8l5eknyZFrbcdZ18+bNrfHYsWNNHLxi4eDBgyYO3jC2MZ9//rk1rqqqMvEjjzyS9vckSTpHYwXA6wA2q6r/UVrLAIzy4lEAlgY/S5RkrG23pLNmdzWAuwD8R0T+ePbZQwCmAfiHiIwGsB3A0BSfJ0oq1rZD0jka+y8AkmK6b4r3iRKPte2WvL9crKioyBrPmjXLxP47NQDA+eefn9Ey/PsvgndbDR6GP3r0aEbLIPJbvXq1NV6zZo2J/XfWCQqelhLcb+3nPy1l0aJF1lwuLkGLGy8XIyInsNkRkRMkeKZ2TheW4SH6K6+80hr7bx7Yo0cPa660tDSTReDIkSMm9p+RDgBTp0418eHDhzP6/gRap6rd406iEERx6klJSYmJ/c8fBuwH3gTvluL/9/3cc89Zcy+//LKJt23bFkqeCZCyrrlmR0ROYLMjIiew2RGRE/Jin920adOscfCBH6kEH2rz/vvvm/jEiRPWnP+UkuCDrwsU99mFJOrLxahR3GdHRG5jsyMiJ+TFZizlBDdjQ8K6ThRuxhKR29jsiMgJbHZE5AQ2OyJyApsdETmBzY6InMBmR0ROYLMjIiew2RGRE9jsiMgJUT9wZy/qH033Fy9OAldz6RjRclyQxLoGkpVPVLmkrOtIr401CxVZm5TrMpkLhSVpv78k5ZOEXLgZS0ROYLMjIifE1exmx7TchjAXCkvSfn9Jyif2XGLZZ0dEFDVuxhKREyJtdiIyQES2iMg2EZkc5bK95c8RkT0issH3XpGIrBCRGu/17Ihy6SAiVSKySUQ2isiEOPOh7MRZ26zr9ETW7ESkOYAXAfwVQDmAYSJSHtXyPXMBDAi8NxnASlUtA7DSG0fhBIBJqloOoCeAcd7fR1z5UIYSUNtzwbpuUpRrdj0AbFPV71T1OIBFACoiXD5UdRWAnwJvVwCY58XzAAyOKJc6Vf3Siw8B2AygNK58KCux1jbrOj1RNrtSAN/7xrXee3ErVtU6L94FoDjqBESkE4BuAKqTkA+dtCTWdux1lLS65gEKH60/NB3p4WkRaQVgMYCJqnow7nyo8LCu60XZ7HYC6OAbt/fei9tuESkBAO91T1QLFpEWqC+IBar6Ttz5UMaSWNus64Aom90aAGUicp6ItARwJ4BlES4/lWUARnnxKABLo1ioiAiA1wFsVtUZcedDWUlibbOug1Q1sh8AAwFsBfAtgL9HuWxv+QsB1AH4L+r3q4wG0Bb1R4dqAPwTQFFEuVyD+lX5fwNY7/0MjCsf/mT9+4yttlnX6f3wCgoicgIPUBCRE9jsiMgJWTW7uC//IsoV1nbhyXifnXeJzFYA/VG/U3QNgGGquim89Iiix9ouTNk8g8JcIgMAIvLHJTIpC0JEeDQkOfaq6jlxJ5FQJ1XbrOtESVnX2WzGJvESGUrf9rgTSDDWdv5KWdc5f7qYiFQCqMz1coiixLrOP9k0u7QukVHV2fBuyczVfcoTTdY26zr/ZLMZm8RLZIjCwNouQBmv2anqCREZD+BDAM0BzFHVjaFlRhQT1nZhivRyMa7uJ8o6TcgDlPMd6zpRUtY1r6AgIiew2RGRE9jsiMgJbHZE5AQ2OyJyApsdETmBzY6InMBmR0ROYLMjIiew2RGRE9jsiMgJOb+fHaWnb9++Jl6wYIE117t3bxNv2bIlspyosLRo0cIa9+rVy8RTp0615q6++upIcooS1+yIyAlsdkTkhLzYjL322mutcdu2bU28ZMmSqNPJiSuuuMLEa9asiTETKlRt2rSxxlVVVSbetWuXNdeuXTtrHJzPR1yzIyInsNkRkRPY7IjICXmxz65Pnz7WuKyszMT5us+uWTP7/zPnnXeeiTt27GjNiUgkOZG7gvvouM+OiChPsdkRkRPyYjN25MiR1nj16tUxZRKekpISazxmzBgTv/XWW9bcN998E0lO5C4XdpVwzY6InMBmR0ROYLMjIifkxT674GkaheC1115LOVdTUxNhJkSAqlrj0047LaZMcqfJLiIic0Rkj4hs8L1XJCIrRKTGez07t2kShY+17ZZ0VpnmAhgQeG8ygJWqWgZgpTcmyjdzwdp2RpObsaq6SkQ6Bd6uANDHi+cB+ATA30LMC127djVxcXFxmF+dCME7UPitWLEiwkzcFVdt54Pu3btb4y+++CKmTMKT6c6wYlWt8+JdAAqvG5GrWNsFKusDFKqqIqKp5kWkEkBltsshilpjtc26zj+ZrtntFpESAPBe96T6g6o6W1W7q2r3VH+GKEHSqm3Wdf7JdM1uGYBRAKZ5r0tDy8gzcOBAE59++ulhf30s/Pse/Xc5Cdq5c2cU6VDDcl7bcTlx4oQ1PnDggImD+5AvuOCCSHKKUjqnniwEsBpAZxGpFZHRqC+E/iJSA6CfNybKK6xtt6RzNHZYiqm+Kd4nygusbbck9gqKzp07p5zbuHFjhJmEZ/r06SYOnk6zdetWEx86dCiynMgd+/fvt8afffaZiQcNGhR1OpErvOuwiIgawGZHRE5gsyMiJyR2n11jkvQQ6datW1vjAQP+vNRyxIgR1twNN9yQ8nsef/xxEwf3rRBR9rhmR0ROYLMjIifk5WZsUVFRRp+75JJLTBx8wEi/fv1M3L59e2uuZcuWJh4+fLg1F7yx6NGjR01cXV1tzR07dszEp5xi/9WvW7eu0dyJotS2bdu4Uwgd1+yIyAlsdkTkBDY7InJCYvfZ+fd9BR8G8sorr5j4oYceSvs7/Xc/Du6z898R4siRI9bcpk2bTDxnzhxrbu3atdb4008/NfHu3butudraWhMH7+TCB2FTktx8881xpxA6rtkRkRPY7IjICWx2ROSExO6zGzt2rIm3b99uzfXq1Suj79yxY4eJ3333XWtu8+bNJg7rSUqVlfYjCs455xwTf/fdd6EsgyhTVVVVJuYtnoiICgSbHRE5IbGbsX5PPfVU3ClkpG/f1Hf3Xrx4cYSZEP0v/26doBYtWljjjh07mji4WylfcM2OiJzAZkdETmCzIyIn5MU+u0K0ZMmSuFMgxwUfmu0XvJzy1FNPzXU6Occ1OyJyApsdETmBm7FEjlq6dKmJg3fd6dKlizWeOHGiif1XN+WTJtfsRKSDiFSJyCYR2SgiE7z3i0RkhYjUeK9n5z5dovCwtt2SzmbsCQCTVLUcQE8A40SkHMBkACtVtQzASm9MlE9Y2w5pstmpap2qfunFhwBsBlAKoALAPO+PzQMwOFdJEuUCa9stJ7XPTkQ6AegGoBpAsarWeVO7ABSHmlkB8h/Ov/DCC625sO60QplxvbY/+ugja1xaWmqN77///ijTyYm0m52ItAKwGMBEVT3o/4erqioimuJzlQAqG5ojSoJMapt1nX/SOvVERFqgvhgWqOo73tu7RaTEmy8BsKehz6rqbFXtrqrdw0iYKEyZ1jbrOv+kczRWALwOYLOqzvBNLQMwyotHAVga/CzZVNX8NGvWzPqh6LG2U/PXqqri+PHj5idfpbMZezWAuwD8R0TWe+89BGAagH+IyGgA2wEMzU2KRDnD2nZIk81OVf8FQFJMp75hG1HCsbbdwu0nInICLxeLyVVXXWWN586dG08iRA1o3bq1Na6oqDBxvt6xh2t2ROQENjsicgI3YyMUvCEiUVIMHWofcD527Jg19j9XOV9xzY6InMBmR0ROYLMjIidwn10OLV++3BrffvvtMWVC1LhVq1ZZ44suusgaHz16NMp0coJrdkTkBDY7InKCqDZ4G7rcLCzFPe8oFut4e6JwsK4TJWVdc82OiJzAZkdETmCzIyInsNkRkRPY7IjICWx2ROQENjsicgKbHRE5gc2OiJzAZkdEToj6rid7Uf8czr94cRK4mkvHiJbjgiTWNZCsfKLKJWVdR3ptrFmoyNqkXJfJXCgsSfv9JSmfJOTCzVgicgKbHRE5Ia5mNzum5TaEuVBYkvb7S1I+secSyz47IqKocTOWiJwQabMTkQEiskVEtonI5CiX7S1/jojsEZENvveKRGSFiNR4r2dHlEsHEakSkU0islFEJsSZD2UnztpmXacnsmYnIs0BvAjgrwDKAQwTkfKolu+ZC2BA4L3JAFaqahmAld44CicATFLVcgA9AYzz/j7iyocylIDangvWdZOiXLPrAWCbqn6nqscBLAJQEeHyoaqrAPwUeLsCwDwvngdgcES51Knql158CMBmAKVx5UNZibW2WdfpibLZlQL43jeu9d6LW7Gq1nnxLgDFUScgIp0AdANQnYR86KQlsbZjr6Ok1TUPUPho/aHpSA9Pi0grAIsBTFTVg3HnQ4WHdV0vyma3E0AH37i9917cdotICQB4r3uiWrCItEB9QSxQ1XfizocylsTaZl0HRNns1gAoE5HzRKQlgDsBLItw+aksAzDKi0cBWBrFQkVEALwOYLOqzog7H8pKEmubdR2kqpH9ABgIYCuAbwH8Pcple8tfCKAOwH9Rv19lNIC2qD86VAPgnwCKIsrlGtSvyv8bwHrvZ2Bc+fAn699nbLXNuk7vh1dQEJETeICCiJzAZkdETmCzIyInsNkRkRPY7IjICWx2ROQENjsicgKbHRE54f8BT5e77QsZAOEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "3\n",
            "uint8\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# cargar los datos MNIST dataset\n",
        "(X_train,y_train) , (X_test, y_test)=mnist.load_data()\n",
        "\n",
        "# 4 imagenes\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0],cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1],cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2],cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[8],cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()\n",
        "print(X_train.shape)\n",
        "print(X_train.ndim)\n",
        "print(X_train.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad2-YgOkSRR3"
      },
      "source": [
        "<a id=\"section3\"></a>\n",
        "# <font color=\"#004D7F\" size=6>3. MLP de línea base</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETF7Dfj_SRR3"
      },
      "source": [
        "Vamos a usar un MLP clásico como base para la comparación con modelos de redes neuronales convolucionales. \n",
        "\n",
        "Importamos las clases, funciones y el dataset MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "FqPaHCeYSRR3"
      },
      "outputs": [],
      "source": [
        "# mas librerias\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "# cargar data\n",
        "(X_train,y_train) , (X_test, y_test)=mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egZaX3nWSRR3"
      },
      "source": [
        "Para un MLP clásico debemos reducir las imágenes a un vector de píxeles. En este caso, las imágenes de tamaño $28 × 28$ serán vectores de entrada de 784 píxeles. \n",
        "\n",
        "Realizamos esta transformación meidante la función `reshape()`. \n",
        "\n",
        "Los valores de los píxeles son números enteros, por lo que los convertimos a punto flotante para poder normalizarlos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9ObrQe4SRR4",
        "outputId": "bc3b8493-6d2a-4201-8916-3dd47ff203e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# escalar los valores enteros a flotantes y hacer una normalizacion de los mismos\n",
        "\n",
        "num_pixels= X_train.shape[1] * X_train.shape[2]# sacar el numero de pixels en total 784\n",
        " \n",
        "#convertir el tensor de imagen a un vector de una sola dimension y convertir a flotante\n",
        "X_train=X_train.reshape(X_train.shape[0],num_pixels).astype('float32') #X_train.shape[0]=60000\n",
        "X_test=X_test.reshape(X_test.shape[0],num_pixels).astype('float32')\n",
        "\n",
        "X_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwqbkWwFSRR4"
      },
      "source": [
        "**Normalizacion**\n",
        "Los valores de los píxeles están en una escala de grises entre 0 y 255. Podemos normalizar los valores de los píxeles en el rango 0 y 1 dividiendo cada valor por el máximo valor, i.e., 255. Se realiza este proceso para que la red neurnal tenga la facilidad de converjer durante el entrenamiento. Para alimentar redes neuronales no se utiliza valores mayores a los pesos de un red, o datos que sean heteregoneos entre ellos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "_LxOGirvSRR4"
      },
      "outputs": [],
      "source": [
        "#pasar datos entre 0 y 1\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDDCCF-3SRR4"
      },
      "source": [
        "Finalmente, la variable de salida es un número entero de 0 a 9. Por tanto, usaremos One-Hot Encoding para transformar el vector de enteros de clase en una matriz binaria. \n",
        "\n",
        "La finalidad de esto es transformar las variables categoricas a numericas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "YvptHL1wSRR4"
      },
      "outputs": [],
      "source": [
        "# se transformo la entrada a binaria tambien se procede a transformar los valores de salida en binarios\n",
        "y_train=np_utils.to_categorical(y_train)\n",
        "y_test=np_utils.to_categorical(y_test)\n",
        "num_classes=y_test.shape[1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo3q3JQLSRR4"
      },
      "source": [
        "Vamos a definir nuestro modelo:\n",
        "1. El número de entradas será el tamaño máximo de pixeles (784)\n",
        "2. Tendrá una capa oculta con el mismo número de neuronas que entradas (784). \n",
        "3. Se utiliza una función de activación ReLU en la capa oculta. \n",
        "4. Se utiliza una función de activación Softmax en la capa de salida. \n",
        "5. La función de pérdida será `categorical_crossentropy`. \n",
        "6. Utilizaremos ADAM para aprender los pesos. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Aqvs8_W4SRR5"
      },
      "outputs": [],
      "source": [
        "# funcion del modelo\n",
        "def baseline_model():\n",
        "    \n",
        "    model=Sequential()\n",
        "    model.add(Dense(num_pixels,input_dim=num_pixels,activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    # Compilar el modelo\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA8TRh2CSRR5"
      },
      "source": [
        "Entrenamos y evaluamos el modelo. \n",
        "1. El modelo se ajusta a más de 10 épocas con actualizaciones cada 200 imágenes. Actualizacion de sus pesos cada 200 imagenes\n",
        "2. Los datos de test se utilizan como conjunto de datos de validación.\n",
        "3. Se utiliza un valor `verbose` de 2. \n",
        "4. Evaluamos en test e imprimimos las métricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mrsb_3HeSRR5",
        "outputId": "a2193b85-3608-4951-826d-bde4c5d458b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 1s - loss: 0.2824 - accuracy: 0.9193 - val_loss: 0.1434 - val_accuracy: 0.9605 - 1s/epoch - 4ms/step\n",
            "Epoch 2/10\n",
            "300/300 - 1s - loss: 0.1106 - accuracy: 0.9676 - val_loss: 0.0893 - val_accuracy: 0.9731 - 866ms/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "300/300 - 1s - loss: 0.0721 - accuracy: 0.9789 - val_loss: 0.0802 - val_accuracy: 0.9763 - 847ms/epoch - 3ms/step\n",
            "Epoch 4/10\n",
            "300/300 - 1s - loss: 0.0518 - accuracy: 0.9849 - val_loss: 0.0722 - val_accuracy: 0.9773 - 833ms/epoch - 3ms/step\n",
            "Epoch 5/10\n",
            "300/300 - 1s - loss: 0.0366 - accuracy: 0.9896 - val_loss: 0.0638 - val_accuracy: 0.9798 - 813ms/epoch - 3ms/step\n",
            "Epoch 6/10\n",
            "300/300 - 1s - loss: 0.0273 - accuracy: 0.9924 - val_loss: 0.0613 - val_accuracy: 0.9809 - 809ms/epoch - 3ms/step\n",
            "Epoch 7/10\n",
            "300/300 - 1s - loss: 0.0198 - accuracy: 0.9950 - val_loss: 0.0593 - val_accuracy: 0.9824 - 777ms/epoch - 3ms/step\n",
            "Epoch 8/10\n",
            "300/300 - 1s - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.0603 - val_accuracy: 0.9809 - 788ms/epoch - 3ms/step\n",
            "Epoch 9/10\n",
            "300/300 - 1s - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.0619 - val_accuracy: 0.9815 - 844ms/epoch - 3ms/step\n",
            "Epoch 10/10\n",
            "300/300 - 1s - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.0608 - val_accuracy: 0.9821 - 809ms/epoch - 3ms/step\n",
            "error del modelo es: 1.79%\n"
          ]
        }
      ],
      "source": [
        "# contruir modelo\n",
        "model = baseline_model()\n",
        "\n",
        "# ajustar el modelo\n",
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=200,verbose=2)\n",
        "\n",
        "# Evaluacion del modelo\n",
        "score=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(\"error del modelo es: %.2f%%\" %(100-score[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section4\"></a>\n",
        "# <font color=\"#004D7F\" size=6> 4. Prediccion de datos</font>"
      ],
      "metadata": {
        "id": "yjDejJqwFV9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_old = X_test.reshape(10000, 28,28)\n",
        "plt.imshow(x_test_old[50], cmap=plt.cm.binary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "c_d0HqnSAsxP",
        "outputId": "42925157-ff24-4784-82d2-f9cb9f2073f6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0f2c2f1130>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predictions=model.predict(X_test)\n",
        "np.argmax(predictions[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaNth7f9Fokh",
        "outputId": "c74b264d-8473-4f27-ad06-95e1902dc2ce"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZIf-_kYSRR5"
      },
      "source": [
        "---\n",
        "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}